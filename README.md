# Artificial Intelligence for the Arts & Humanities (A) Portfolio
**Course:** AI for the Arts and Humanities (A)  
**Academic year:** 2025–26  
**Student GUID:** 2909319

## About this repository
This repository contains my portfolio for the course *AI for the Arts and Humanities (A)*.  
It brings together Jupyter notebooks, code, text, and media (images / audio / video) to:

- explore basic programming concepts using Python,
- explain a machine learning workflow to a non-technical arts and humanities audience,
- critically reflect on opportunities and risks of AI in cultural and social contexts,
- design a small, creative application concept using a large language model (LLM).

The portfolio is not just a record of lab tasks. It is meant to be *read* as a guided story about how I learned to read code, think about media as data, understand machine learning, and imagine uses of LLMs in the arts and humanities.

## Learning objectives

By the end of this portfolio, a reader should be able to see how I:

1. **Read and make sense of code**  
   - Identify basic programming concepts (variables, functions, loops, data structures).  
   - Translate small code snippets into plain English or pseudocode.

2. **Understand and explain a machine learning workflow**  
   - Describe key steps (data, features, training, validation, evaluation) using analogies and visuals suitable for non-technical audiences.  
   - Reflect on what the model seems to do well, where it fails, and why that matters.

3. **Think critically about AI in society and culture**  
   - Connect coding and machine learning examples to issues such as bias, fairness, explainability, creativity, and power.  
   - Use course readings and external sources to support reflections.

4. **Communicate with an arts & humanities audience**  
   - Use markdown, comments, and media to make notebooks readable and engaging for people who may “freak out when they see code”.  
   - Structure notebooks so that someone can follow the narrative without needing to run every cell.

5. **Reflect on AI-assisted learning**  
   - Show how I used Microsoft Copilot (and similar tools) to learn Python and understand machine learning.  
   - Discuss both benefits and limitations of relying on AI support.
  
## What is in this repository?

This section gives a quick overview of the main files and how they fit together.  

- **`coding_exercises.ipynb`**  
  Simple Python exercises (printing, variables, lists, loops, functions).  
  I use markdown cells to explain what each block of code is doing and occasionally rewrite it in plain English.  
  The goal is to show that I can *read* code and talk through it, not just run it.

- **`Machine-Learning-by-Example-from-Start-to-End.ipynb`**  
  A walkthrough of a complete machine learning workflow. 
  I focus on:
  - what happens at each stage (data, splitting, training, evaluation),  
  - how to interpret the output in words,  
  - what kinds of mistakes or biases might appear in this kind of model.

- **`Part4_LLM_Design.ipynb`**  
  A small design concept using a large language model (LLM).  
  Here I outline:
  - the imagined user and scenario,  
  - how the LLM-based application would work,  
  - what the risks are and how we might reduce them.

### 2. Media and other files
Detailed attribution and licensing information for the audio and image files is provided in the relevant notebooks.

- **`audio1.mid`** and **`audio2.ogg`**  
  Audio files used in the notebooks to experiment with loading and playing media in Jupyter, and to
  think about how “media as data” can be processed by code.
  
- **`datasets/`**
  Tabular datasets used in the machine-learning notebook (for example the housing data from the lab materials).  
  These are included so that the notebooks can be run reproducibly from this repository.

- **`picture1.jpg`**  
  An image used as a simple example for displaying or processing visual media.

- **`LICENSE`**  
  The licence file for this repository.

- **`.ipynb_checkpoints/`**  
  Automatically created by Jupyter; you can ignore this folder when reading the portfolio.

## How to read this portfolio

You do **not** need to run every cell to understand what is going on.  
If you prefer to just read, I suggest this order:

1. **Start with the basic Python notebook**  
   - Skim the code blocks and focus on the markdown explanations.  
   - Pay special attention to places where I pause and say what I found confusing at first.

2. **Then move to the machine learning workflow notebook**  
   - Follow the steps from loading the data to evaluating the model.  
   - Look at the comments where I try to interpret the numbers and graphs in everyday language.

3. **Finish with the LLM design notebook**  
   - Here the focus is less on code and more on design thinking.  
   - I try to connect what we did in the earlier notebooks to a more open-ended question:  
     *how should we actually use these tools in arts and humanities contexts?*

Throughout the notebooks I use headings, short paragraphs, bullet points and occasional diagrams so that people who are new to coding can follow the main ideas without getting lost in syntax.

## How I used AI tools (Copilot and others)

AI tools play a double role in this portfolio: they are both the **topic** and part of the **method**.

In several notebooks you will see:

- my original prompts to Microsoft Copilot,  
- Copilot’s suggestions or completions,  
- my comments on what I accepted, changed, or rejected.

I try to be clear when a piece of code or wording comes from an AI suggestion rather than from me.  
Sometimes the tool was helpful (for example, fixing syntax errors or suggesting a more efficient loop). Sometimes it produced something that looked confident but was not very appropriate for the task.

The aim is not to show that AI is “good” or “bad”, but to show that using these tools always involves choices and interpretation.
